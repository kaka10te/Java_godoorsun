Automatically generated by Mendeley Desktop 1.18
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Sun2014,
abstract = {Cooperation and competition (jointly called {\&}{\#}x201C;coopetition{\&}{\#}x201D;) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., {\&}{\#}x201C;topic leaders{\&}{\#}x201D;) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).},
author = {Sun, Guodao and Wu, Yingcai and Liu, Shixia and Peng, Tai Quan and Zhu, Jonathan J.H. and Liang, Ronghua},
doi = {10.1109/TVCG.2014.2346919},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1753{\_}20tvcg12-sun-2346919.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Topic coopetition,information diffusion,information propagation,time-based visualization},
number = {12},
pages = {1753--1762},
pmid = {26356889},
title = {{EvoRiver: Visual analysis of topic coopetition on social media}},
volume = {20},
year = {2014}
}
@article{Goffin2014,
abstract = {We present an exploration and a design space that characterize the usage and placement of word-scale visualizations within text documents. Word-scale visualizations are a more general version of sparklines--small, word-sized data graphics that allow meta-information to be visually presented in-line with document text. In accordance with Edward Tufte's definition, sparklines are traditionally placed directly before or after words in the text. We describe alternative placements that permit a wider range of word-scale graphics and more flexible integration with text layouts. These alternative placements include positioning visualizations between lines, within additional vertical and horizontal space in the document, and as interactive overlays on top of the text. Each strategy changes the dimensions of the space available to display the visualizations, as well as the degree to which the text must be adjusted or reflowed to accommodate them. We provide an illustrated design space of placement options for word-scale visualizations and identify six important variables that control the placement of the graphics and the level of disruption of the source text. We also contribute a quantitative analysis that highlights the effect of different placements on readability and text disruption. Finally, we use this analysis to propose guidelines to support the design and placement of word-scale visualizations.},
author = {Goffin, Pascal and Willett, Wesley and Fekete, Jean Daniel and Isenberg, Petra},
doi = {10.1109/TVCG.2014.2346435},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2291{\_}20tvcg12-goffin-2346435.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Design space,Glyphs,Information visualization,Sparklines,Text visualization,Word-scale visualizations},
number = {12},
pages = {2291--2300},
pmid = {26356943},
title = {{Exploring the placement and design of word-scale visualizations}},
volume = {20},
year = {2014}
}
@article{Eppler2014,
author = {Eppler, Martin J. and Kernbach, Sebastian and Wiederkehr, Benjamin and Gassner, Peter},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/eppler.pdf:pdf},
journal = {IEEE Information Visualization},
title = {{The Confluence Diagram: Embedding Knowledge in Interaction Constraints}},
year = {2014}
}
@article{Gotz2014,
abstract = {(a) (b) (c) (d) (e) (f) Fig. 1. A screenshot of DecisionFlow being used to analyze electronic medical data. This view (b-d) summarizes the medical records for 514 cardiology patients that match (a) the user-defined query. The query results include over 113,000 individual events of more than 1,600 distinct event types. (e) Highlighted is a subgroup of patients who developed heart failure at significantly higher rates (p {\textless} 0.01) than peers who received (f) a particular type of lab test earlier in the episode. Abstract— Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.},
author = {Gotz, David and Stavropoulos, Harry},
doi = {10.1109/TVCG.2014.2346},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1783{\_}20tvcg12-gotz-2346682.pdf:pdf},
issn = {1077-2626},
keywords = {Flow Diagrams,Index Terms—Information Visualization,Medical Informatics,Temporal Event Sequences,Visual Analytics},
number = {1},
pages = {1783--1792},
title = {{DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data}},
url = {http://vis.cs.ucdavis.edu/vis2014papers/TVCG/papers/1783{\_}20tvcg12-gotz-2346682.pdf},
volume = {20},
year = {2014}
}
@article{ODonoghue2014,
author = {O'Donoghue, Sean I. and Sabir, Kenneth and Kalemanov, Maria and Stolte, Christian and Perdigao, Nelson and Buske, Fabian A. and Heinrich, Julian and Rost, Burkhard and Schafferhans, Andrea},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/odonoghue.pdf:pdf},
journal = {IEEE Information Visualization},
title = {{Aquaria: Integrating Sequence and Structure ´}},
year = {2014}
}
@article{VanDenElzen2014,
abstract = {Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.},
author = {{Van Den Elzen}, Stef and {Van Wijk}, Jarke J.},
doi = {10.1109/TVCG.2014.2346441},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2310{\_}20tvcg12-vandenelzen-2346441.pdf:pdf},
isbn = {1077-2626 VO - 20},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Direct manipulation,Interaction,Multivariate networks,Selections of interest},
number = {12},
pages = {2310--2319},
pmid = {26356945},
title = {{Multivariate network exploration and presentation: From detail to overview via selections and aggregations}},
volume = {20},
year = {2014}
}
@article{Ferdous2014,
abstract = {See, stats, and : http : / / www . researchgate . net / publication / 270883064 Using Difficulty CONFERENCE READS 18 2 , INCLUDING : Nahid Florida 1 SEE Available : Nahid Retrieved : 21 ABSTRACT Changes in human pupil size are known to be correlated with task difficulty [ 1 ] . Here we explore the opportunity of using eye tracking to measure task difficulty in the specific context of data visualization . In particular , we use a controlled eye - tracking study to investigate the difference between two types of task difficulty , mental difficulty and visual difficulty , explore the time frames at which pupil size responds to changes in task difficulty , and investigate if pupil size can provide qualitative hints as to which part of a task people find difficult . We found that eye tracker reveals mental difficulty more precisely than visual difficulty (Fig . 5) . We also found a set of patterns of pupil size changes that are related with mental activity and we show that using pupil size in conjunction with gaze coordinates lets us make inferences about user cognition that would not be possible if looking at gaze coordinates alone .},
author = {Ferdous, Nahid and Jianu, Radu},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/ferdous.pdf:pdf},
journal = {IEEE Information Visualization},
keywords = {eye tracker,gaze point,pupil size},
number = {October},
pages = {1--2},
title = {{Using Pupil Size as an Indicator for Task Difficulty in Data Visualization}},
year = {2014}
}
@article{Zhao2014,
author = {Zhao, Ying and Peng, Yanni and Huang, Wei and Li, Yong and Zhou, Fangfang and Liao, Zhifang and Zhang, Kang},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Zhao.pdf:pdf},
isbn = {9781479962273},
keywords = {digital forensics,parallel coordinates,spatial and temporal analysis,trajectory data,transaction data,visual analysis},
pages = {371--372},
title = {{A Collaborative Visual Analytics of Trajectory and Transaction Data for Digital Forensics}},
volume = {1},
year = {2014}
}
@article{Borgo2014,
author = {Borgo, Rita and Chen, Min and {Eamon Maguire}, Sine McDougall and Ward, Matthew},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/tutorials/Glyph-based{\_}Visualization/borgo.pdf:pdf},
journal = {IEEE VIS Tutorials},
keywords = {and deliver effectual communication,glyphs have served as,historically,in science and engi-,many disciplines,other automated mechanisms,such as schematic diagrams,to others,visual languages in},
title = {{Glyph-based Visualization}},
url = {http://ieeevis.org/year/2014/info/overview-amp-topics/accepted-tutorials},
year = {2014}
}
@article{Yuan2015,
author = {Yuan, Xiaoru and Wang, Zhenhuang and Liu, Zipeng and Guo, Cong and Ai, Hongwei and Ren, Donghao},
doi = {10.1109/VAST.2014.7042535},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/posters/yuan.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
pages = {291--292},
title = {{Visualization of social media flows with interactively identified key players}},
year = {2015}
}
@article{Accorsi2014,
author = {Accorsi, Pierre and Ber, Florence Le},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/accorsi.pdf:pdf},
isbn = {9781479962273},
keywords = {spatiotemporal data mining and,visual analytics,visualization,water quality},
pages = {123--132},
title = {{HydroQual : Visual Analysis of River Water Quality}},
year = {2014}
}
@article{Scheepens2014,
author = {Scheepens, Roeland and Michels, Steffen and van de Wetering, Huub and van Wijk, Jarke J},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/scheepens.pdf:pdf},
journal = {IEEE Information Visualization},
number = {August},
title = {{Rationale Visualization for Decision Support}},
year = {2014}
}
@article{Shi2014,
abstract = {The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.},
author = {Shi, Conglei and Wu, Yingcai and Liu, Shixia and Zhou, Hong and Qu, Huamin},
doi = {10.1109/TVCG.2014.2346912},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1733{\_}20tvcg12-shi-2346912.pdf:pdf},
isbn = {1077-2626 VO  - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Time-series visualization,log data visualization,stacked graphs,text visualization},
number = {12},
pages = {1733--1742},
title = {{LoyalTracker: Visualizing loyalty dynamics in search engines}},
volume = {20},
year = {2014}
}
@article{Boy2014a,
author = {Boy, Jeremy and Fekete, Jean-Daniel},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/boy.pdf:pdf},
journal = {IEEE Information Visualization},
pages = {1--2},
title = {{The CO2 Pollution Map: Lessons Learned from Designing a Visualization that Bridges the Gap between Visual Communication and Information Visualization}},
year = {2014}
}
@article{Behrisch2015a,
abstract = {The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user's preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.},
author = {Behrisch, Michael and Korkmaz, Fatih and Shao, Lin and Schreck, Tobias},
doi = {10.1109/VAST.2014.7042480},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/behrisch/behrisch.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Interesting View Problem,Relevance Feedback,User Preference Model,View Space Exploration Framework},
pages = {43--52},
title = {{Feedback-driven interactive exploration of large multidimensional data supported by visual classifier}},
year = {2015}
}
@article{Thomas2014,
abstract = {The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.},
author = {Thomas, Dilip Mathew and Natarajan, Vijay},
doi = {10.1109/TVCG.2014.2346332},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/SupplementalMaterial/2427{\_}supMat/2427{\_}supMat.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Contour tree,Data exploration,Scalar field visualization,Symmetry detection},
number = {12},
pages = {2427--2436},
title = {{Multiscale symmetry detection in scalar fields by clustering contours}},
volume = {20},
year = {2014}
}
@article{Yashaswi2015,
author = {Yashaswi, P. and Navya, Yarrabelly and Chikka, Veera Raghavendra},
doi = {10.1109/VAST.2014.7042570},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Yashaswi.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
pages = {369--370},
title = {{Regular and unusual data visualization IIIT-H}},
year = {2015}
}
@article{Winters2014,
author = {Winters, Kirsten M and Lach, Denise and Cushing, Judith B},
doi = {10.1145/2669557.2669573},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p016-winters.pdf:pdf},
isbn = {978-1-4503-3209-5},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization},
keywords = {ethnographic methods,evaluation,participant observation,software development,visualization},
pages = {16--22},
title = {{Considerations for Characterizing Domain Problems}},
url = {http://doi.acm.org/10.1145/2669557.2669573},
year = {2014}
}
@article{Dietrich2015,
abstract = {While many sports use statistics and video to analyze and improve game play, baseball has led the charge throughout its history. With the advent of new technologies that allow all players and the ball to be tracked across the entire field, it is now possible to bring this understanding to another level. From discrete positions across time, we present techniques to reconstruct entire baseball games and visually explore each play. This provides opportunities to not only derive new metrics for the game, but also allow us to investigate existing measures with targeted visualizations. In addition, our techniques allow users to filter on demand so specific situations can be analyzed both in general and according to those situations. We show that gameplay can be accurately reconstructed from the raw position data and discuss how visualization and statistical methods can combine to better inform baseball analyses.},
author = {Dietrich, Carlos and Koop, David and Vo, Huy T. and Silva, Claudio T.},
doi = {10.1109/VAST.2014.7042478},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/dietrich.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {baseball,baseball metrics,event data,game reconstruction,sports analytics,sports visualization},
pages = {23--32},
title = {{Baseball4D: A tool for baseball game reconstruction {\&} visualization}},
year = {2015}
}
@article{VanWijk2014,
abstract = {A regular map is a symmetric tiling of a closed surface, in the sense that all faces, vertices, and edges are topologically indistinguishable. Platonic solids are prime examples, but also for surfaces with higher genus such regular maps exist. We present a new method to visualize regular maps. Space models are produced by matching regular maps with target shapes in the hyperbolic plane. The approach is an extension of our earlier work. Here a wider variety of target shapes is considered, obtained by duplicating spherical and toroidal regular maps, merging triangles, punching holes, and gluing the edges. The method produces about 45 new examples, including the genus 7 Hurwitz surface.},
author = {{Van Wijk}, Jarke J.},
doi = {10.1109/TVCG.2014.2352952},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2614{\_}20tvcg12-vanwijk-2352952.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {mathematical visualization,regular maps,surface topology,tessellation,tiling},
number = {12},
pages = {2614--2623},
pmid = {26356975},
title = {{Visualization of regular maps: The chase continues}},
volume = {20},
year = {2014}
}
@article{McKenna2014,
author = {McKenna, Sean and Meyer, Miriah and Gregg, Christopher and Gerber, Samuel},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/mckenna.pdf:pdf},
journal = {IEEE Information Visualization},
number = {c},
title = {{s-CorrPlot: Encoding and Exploring Correlation}},
volume = {2},
year = {2014}
}
@article{Smit2014,
author = {Smit, Noeska and Hofstede, Cees-Wilem and Eisemann, Elmar and Kraima, Annelot and Botha, Charl and Jansma, Daniel and Vilanova, Anna and de Ruiter, Marco},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/smit.pdf:pdf},
journal = {IEEE Scientific Visualization},
pages = {1--2},
title = {{The Online Anatomical Human: Anatomical Knowledge Exchange on the Web}},
year = {2014}
}
@article{Godwin2014,
author = {Godwin, Alex and Sainath, Anand and Jayakumar, Sanjay Obla and Nabhi, Vivek and Raut, Sagar and Stasko, John},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/godwin.pdf:pdf},
journal = {IEEE Information Visualization},
keywords = {crime data,non-expert,personal routes,spatio-temporal analysis,timelines,visualization},
pages = {3--4},
title = {{Exploring Spatio-Temporal Data as Personal Routes}},
year = {2014}
}
@article{Gyulassy2014,
abstract = {Morse-Smale (MS) complexes have been gaining popularity as a tool for feature-driven data analysis and visualization. However, the quality of their geometric embedding and the sole dependence on the input scalar field data can limit their applicability when expressing application-dependent features. In this paper we introduce a new combinatorial technique to compute an MS complex that conforms to both an input scalar field and an additional, prior segmentation of the domain. The segmentation constrains the MS complex computation guaranteeing that boundaries in the segmentation are captured as separatrices of the MS complex. We demonstrate the utility and versatility of our approach with two applications. First, we use streamline integration to determine numerically computed basins/mountains and use the resulting segmentation as an input to our algorithm. This strategy enables the incorporation of prior flow path knowledge, effectively resulting in an MS complex that is as geometrically accurate as the employed numerical integration. Our second use case is motivated by the observation that often the data itself does not explicitly contain features known to be present by a domain expert. We introduce edit operations for MS complexes so that a user can directly modify their features while maintaining all the advantages of a robust topology-based representation.},
author = {Gyulassy, Attila and G{\"{u}}nther, David and Levine, Joshua A. and Tierny, Julien and Pascucci, Valerio},
doi = {10.1109/TVCG.2014.2346434},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2595{\_}20tvcg12-gyulassy-2346434.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Computational topology,Data analysis,Morse-Smale complex},
number = {12},
pages = {2595--2603},
title = {{Conforming Morse-Smale complexes}},
volume = {20},
year = {2014}
}
@article{Okoe2015,
abstract = {We present GraphUnit, a framework and online service that automates the process of designing, running and analyzing results of controlled user studies of graph visualizations by leveraging crowdsourcing and a set of evaluation modules based on a graph task taxonomy. User studies play an important role in visualization research but conducting them requires expertise and is time consuming. GraphUnit simplifies the evaluation process by allowing visualization designers to easily configure user studies for their web-based graph visualizations, deploy them online, use Mechanical Turk to attract participants, collect user responses and store them in a database, and analyze incoming results automatically using appropriate statistical tools and graphs. We demonstrate the effectiveness of GraphUnit by replicating two published evaluation studies on network visualization, and showing that these studies could be configured in less than an hour. Finally, we discuss how GraphUnit can facilitate quick evaluations of alternative graph designs and thus encourage the frequent use of user studies to evaluate design decisions in iterative development processes. [ABSTRACT FROM AUTHOR]},
author = {Okoe, Mershack and Jianu, Radu},
doi = {10.1111/cgf.12657},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/okoe.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {Graph evaluation,automating graph evaluation,crowdsourcing graphs,graph user studies},
number = {3},
pages = {451--460},
title = {{GraphUnit: Evaluating Interactive Graph Visualizations Using Crowdsourcing}},
volume = {34},
year = {2015}
}
@article{Stasko2014,
abstract = {Existing evaluations of data visualizations often employ a series of low-level, detailed questions to be answered or benchmark tasks to be performed. While that methodology can be helpful to determine a visualization's usability, such evaluations overlook the key benefits that visualization uniquely provides over other data analysis methods. I propose a value-driven evaluation of visualizations in which a person illustrates a system's value through four important capabilities: minimizing the time to answer diverse questions, spurring the generation of insights and insightful questions, conveying the essence of the data, and generating confidence and knowledge about the data's domain and context. Additionally, I explain how interaction is instrumental in creating much of the value that can be found in visualizations.},
author = {Stasko, John},
doi = {10.1145/2669557.2669579},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p046-stasko.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
keywords = {data visualization,evaluation,interaction,value},
pages = {46--53},
title = {{Value-driven evaluation of visualizations}},
url = {http://dl.acm.org/citation.cfm?doid=2669557.2669579},
year = {2014}
}
@article{Gortana2014,
abstract = {Isochrone maps are an established method to depict areas of equal travel time, and have been used in transportation planning since the early 20th century. In recent years, interactive isochrone maps al- lowed users to select areas of interest, or explore temporal mobility patterns for different modes of transport. However, conventional isochrone maps depict one traffic situation at a time. Our visualization approach unifies isochrone maps with time- varying travel data, and instead of showing multiple isolines for different travel times, we show multiple isolines for different times of day in order to reveal time-dependent spatial travel variance. In this paper, we present Isoscope, a web application that provides an interactive map for casual exploration of urban mobility patterns. Through its aesthetic visual form and its simple interface we strive to support people investigating travel time in their own city. We will describe our design goals, elaborate on the design and implementa- tion of our prototype, and discuss limitations and future extensions of the system.},
author = {Gortana, Flavio and Kaim, Sebastian and von Lupin, Marti and Nagel, Till},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/gortana.pdf:pdf},
journal = {IEEE Information Visualization},
pages = {1--2},
title = {{Isoscope - Visualizing temporal mobility variance with isochrone maps}},
year = {2014}
}
@article{Zhang2015,
abstract = {This article describes a real-time visual analytics process based on microblog and emergency call data to solve VAST 2014 Mini Challenge 3. We extended SMART system (Social Media Analytics and Reporting Toolkit), developed by the U.S. Department of Homeland Security's VACCINE Center. Our system consists of multiple linked views to allow the analyst monitor topic evolution, identify influential microblog users, observe geo-location patterns and examine correlations among different data sources. Extensions to our previous work include a time series view, a reply/retweet networks view, and integration of emergency call data.},
author = {Zhang, Jiawei and Afzal, Shehzad and Breunig, Dallas and Xia, Jing and Zhao, Jieqiong and Sheeley, Isaac and Christopher, Joseph and Ebert, David S. and Guo, Chen and Xu, Shang and Yu, Jim and Wang, Qiaoying and Wang, Chen and Qian, Zhenyu and Chen, Yingjie},
doi = {10.1109/VAST.2014.7042582},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Zhang.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Microblog,Multiple Linked Views,Spatiotemporal Analysis,Visual Analytics},
pages = {393--394},
title = {{Real-time identification and monitoring of abnormal events based on microblog and emergency call data using SMART}},
year = {2015}
}
@article{Ahmed2014,
abstract = {The widespread web-based connectivity of people all over the world has yielded new opportunities to recruit humans for visual analytics evaluation and for an abundance of other tasks. Known as crowdsourcing, humans typically receive monetary incentives to participate. However, while these payments are small per evaluation, the cost can add up for realistically-sized studies. Furthermore, since the reward is money, the quality of the evaluation can suffer. Our approach uses radically different incentives, namely entertainment, pleasure, and the feeling of success. We propose a theory, methodology and framework that can allow any visual analytics researcher to turn his/her evaluation task into an entertaining online game. First experiences with a prototype have shown that such an approach allows tenthousands of evaluations to be done in a matter of days at no cost which is completely unthinkable with conventional methods. Copyright {\textcopyright} 2014 ACM.},
author = {Ahmed, Nafees and Mueller, Klaus},
doi = {10.1145/2669557.2669574},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p078-ahmed.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
keywords = {evaluation,gamification,user studies,visual analytics},
pages = {78--86},
title = {{Gamification as a paradigm for the evaluation of visual analytics systems}},
url = {http://dl.acm.org/citation.cfm?id=2669557.2669574},
volume = {10-Novembe},
year = {2014}
}
@article{Cui2014,
author = {Cui, Weiwei and Liu, Shixia and Wu, Zhuofeng and Wei, Hao},
doi = {10.1109/TVCG.2014.2346},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2281{\_}20tvcg12-cui-2346433.pdf:pdf},
issn = {1077-2626},
journal = {Ieee Transactions on Visualization and Computer Graphics},
number = {12},
pages = {2281--2290},
title = {{How Hierarchical Topics Evolve in Large Text Corpora}},
volume = {20},
year = {2014}
}
@article{Alexander2015,
abstract = {Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher's own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach. View full abstract},
author = {Alexander, Eric and Kohlmann, Joe and Valenza, Robin and Witmore, Michael and Gleicher, Michael},
doi = {10.1109/VAST.2014.7042493},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/alexander.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Text visualization,topic modeling},
pages = {173--182},
title = {{Serendip: Topic model-driven visual exploration of text corpora}},
year = {2015}
}
@article{Roberts2014,
author = {Roberts, Jonathan C and Walker, Rick T and Roberts, Lukas and Laramee, Robert S and Ritsos, Panagiotis D},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/roberts.pdf:pdf},
journal = {IEEE Information Visualization},
keywords = {information visualization,interac-,visual analytics},
title = {{Exploratory Visualization through Copy, Cut and Paste}},
year = {2014}
}
@article{Wang2014d,
abstract = {In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.},
author = {Wang, Zuchao and Ye, Tangzhi and Lu, Min and Yuan, Xiaoru and Qu, Huamin and Yuan, Jacky and Wu, Qianliang},
doi = {10.1109/TVCG.2014.2346746},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1813{\_}20tvcg12-wang-2346746.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Dynamic Graph Visualization,Sparse Traffic Trajectory,Traffic Congestion,Traffic Visualization},
number = {12},
pages = {1813--1822},
pmid = {26356895},
title = {{Visual exploration of sparse traffic trajectory data}},
volume = {20},
year = {2014}
}
@article{Kucher2014,
abstract = {Figure 1: The web-based user interface of our visual survey. By using the interaction panel on the left hand side, researchers can look for specific visualization techniques and filter out entries with respect to a set of categories (cf. the taxonomy given in Sect. 2). Details for a selected entry are shown by clicking on a thumbnail image in the main view. The survey contains 100 categorized visualization techniques by June 24, 2014. ABSTRACT Text visualization has become a growing and increasingly impor-tant subfield of information visualization. Thus, it is getting harder for researchers to look for related work with specific tasks or visual metaphors in mind. In this poster, we present an interactive visual survey of text visualization techniques that can be used for the pur-poses of search for related work, introduction to the subfield and gaining insight into research trends.},
author = {Kucher, Kostiantyn},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/kucher.pdf:pdf},
journal = {InfoVis},
keywords = {interaction,survey,text visualization,visualization,web-based systems},
number = {November 2014},
title = {{Text Visualization Browser : A Visual Survey of Text Visualization Techniques}},
year = {2014}
}
@article{Gomez2015,
abstract = {—We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efficiently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight-and task-based evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predefined search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include findings that might have been difficult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-defined tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method.},
author = {Gomez, Steven R. and Guo, Hua and Ziemkiewicz, Caroline and Laidlaw, David H.},
doi = {10.1109/VAST.2014.7042482},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/gomez.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Evaluation methodology,information visualization,insight-based evaluation,network visualization,visual analytics},
pages = {63--72},
title = {{An insight- and task-based methodology for evaluating spatiotemporal visual analytics}},
year = {2015}
}
@article{Sumengen2014,
author = {Sumengen, Selcuk and Serin, Ekrem and Balcisoy, Selim S.},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/sumengen.pdf:pdf},
journal = {IEEE Scientific Visualization},
title = {{Entropy Guided Visualization And Analysis Of Multivariate Spatio-Temporal Data Generated By Physically Based Simulation}},
year = {2014}
}
@article{Lunzer2014,
abstract = {Figure 1: Checking how bin offset influences the shape of a histogram for a small data set. Histograms for ten offset values are combined on the main chart using translucent overlay; the user has also steered the dashed-red probe region to display this part of the respective charts in a small-multiples view. On the far right we show how mousing over one of the small-multiples panes highlights the corresponding histogram on the main chart, and also shows the outline of that histogram on the other panes. ABSTRACT Graphics such as statistical charts are crucial tools for communicat-ing the essence of data, but require care in their construction: a chart for a given data set could appear to tell a range of stories, depending just on parameter values used in generating the chart. We are in-vestigating how providing an interactive history of chart-parameter manipulations could encourage people to check the robustness of any story a chart appears to show. Our hope is that this work will be of value to chart creators and consumers alike.},
author = {Lunzer, Aran and McNamara, Amelia},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/lunzer.pdf:pdf},
journal = {IEEE Information Visualization},
keywords = {2,5,comparisons,exploratory data analysis,graphical user interfaces,gui,h,index terms,information interfaces and presentation,interaction history,junctive interfaces,multiple views,small multiples,sub-,user interfaces},
title = {{It Ain't Necessarily So: Checking Charts for Robustness}},
year = {2014}
}
@article{Isaacs2014a,
abstract = {Searching a large document collection to learn about a broad subject involves the iterative process of figuring out what to ask, filtering the results, identifying useful documents, and deciding when one has covered enough material to stop searching. We are calling this activity “discoverage,” discovery of relevant material and tracking coverage of that material. We built a visual analytic tool called Footprints that uses multiple coordinated visualizations to help users navigate through the discoverage process. To support discovery, Footprints displays topics extracted from documents that provide an overview of the search space and are used to construct searches visuospatially. Footprints allows users to triage their search results by assigning a status to each document (To Read, Read, Useful), and those status markings are shown on interactive histograms depicting the user's coverage through the documents across dates, sources, and topics. Coverage histograms help users notice biases in their search and fill any gaps in their analytic process. To create Footprints, we used a highly iterative, user-centered approach in which we conducted many evaluations during both the design and implementation stages and continually modified the design in response to feedback.},
author = {Isaacs, Ellen and Damico, Kelly and Ahern, Shane and Bart, Eugene and Singhal, Mudita},
doi = {10.1109/TVCG.2014.2346743},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1793{\_}20tvcg12-isaacs-2346743.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {coverage tracking,discoverage,discovery search visualization,document triage,interactive histograms,visual cues},
number = {12},
pages = {1793--1802},
title = {{Footprints: A visual search tool that supports discovery and coverage tracking}},
volume = {20},
year = {2014}
}
@article{Kwon2014,
author = {Kwon, Kyeong-An and Shastri, Dvijesh and Pavlidis, Ioannis},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/kwon.pdf:pdf},
journal = {IEEE Information Visualization},
number = {Figure 1},
pages = {1--2},
title = {{Information Visualization in Affective User Studies}},
year = {2014}
}
@article{Behrisch2015,
abstract = {The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user's preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.},
author = {Behrisch, Michael and Korkmaz, Fatih and Shao, Lin and Schreck, Tobias},
doi = {10.1109/VAST.2014.7042480},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/behrisch.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Interesting View Problem,Relevance Feedback,User Preference Model,View Space Exploration Framework},
pages = {43--52},
title = {{Feedback-driven interactive exploration of large multidimensional data supported by visual classifier}},
year = {2015}
}
@article{Liang2014b,
author = {Liang, Yanhua and Fang, Shiaofen and Brandstatter, Taylor and Cai, Chengtao and Wang, Yang and West, John D and Saykin, Andrew J and Shen, Li},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/liang.pdf:pdf},
journal = {IEEE Scientific Visualization},
keywords = {brain connectome,classification,color model,feature,neuroimaging,visualization},
pages = {4--5},
title = {{Brain Connectome Visualization for Feature Classification}},
year = {2014}
}
@article{Gunther2014d,
abstract = {Data acquisition, numerical inaccuracies, and sampling often introduce noise in measurements and simulations. Removing this noise is often necessary for efficient analysis and visualization of this data, yet many denoising techniques change the minima and maxima of a scalar field. For example, the extrema can appear or disappear, spatially move, and change their value. This can lead to wrong interpretations of the data, e.g., when the maximum temperature over an area is falsely reported being a few degrees cooler because the denoising method is unaware of these features. Recently, a topological denoising technique based on a global energy optimization was proposed, which allows the topology-controlled denoising of 2D scalar fields. While this method preserves the minima and maxima, it is constrained by the size of the data. We extend this work to large 2D data and medium-sized 3D data by introducing a novel domain decomposition approach. It allows processing small patches of the domain independently while still avoiding the introduction of new critical points. Furthermore, we propose an iterative refinement of the solution, which decreases the optimization energy compared to the previous approach and therefore gives smoother results that are closer to the input. We illustrate our technique on synthetic and real-world 2D and 3D data sets that highlight potential applications.},
author = {G{\"{u}}nther, David and Jacobson, Alec and Reininghaus, Jan and Seidel, Hans Peter and Sorkine-Hornung, Olga and Weinkauf, Tino},
doi = {10.1109/TVCG.2014.2346432},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2585{\_}20tvcg12-guenther-2346432.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Numerical optimization,Scalar fields,Topology},
number = {12},
pages = {2585--2594},
title = {{Fast and memory-efficient topological denoising of 2D and 3D scalar fields}},
volume = {20},
year = {2014}
}
@article{Matkovic2014,
abstract = {In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a na{\&}{\#}x00A8;{\&}{\#}x0131;ve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the {\&}{\#}x201C;best{\&}{\#}x201D; points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.},
author = {Matkovi{\'{c}}, Kre{\v{s}}imir and Gra{\v{c}}anin, Denis and Splechtna, Rainer and Jelovi{\'{c}}, Mario and Stehno, Benedikt and Hauser, Helwig and Purgathofer, Werner},
doi = {10.1109/TVCG.2014.2346744},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1803{\_}20tvcg12-matkovic-2346744.pdf:pdf},
isbn = {1077-2626 VO  - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Automatic Optimization,Integrated Design Environment,Interactive Visual Analysis,Simulation,Visual Steering},
number = {12},
pages = {1803--1812},
pmid = {26356894},
title = {{Visual analytics for complex engineering systems: Hybrid visual steering of simulation ensembles}},
volume = {20},
year = {2014}
}
@article{Seo2014,
author = {Seo, Daeil and Yoo, Byounghyun and Ko, Heedong},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/seo.pdf:pdf},
journal = {IEEE Scientific Visualization},
keywords = {3,6,computer graphics,i,immersive visual interaction,index terms,interaction,level-of-detail,methodology and,pan,spatiotemporal content,techniques,zoom and},
title = {{Visual Interaction for Spatiotemporal Content using Zoom and Pan with Level - of - D etail}},
year = {2014}
}
@article{Lindow2014,
abstract = {{\textcopyright} 1995-2012 IEEE. The most popular molecular surface in molecular visualization is the solvent excluded surface (SES). It provides information about the accessibility of a biomolecule for a solvent molecule that is geometrically approximated by a sphere. During a period of almost four decades, the SES has served for many purposes-including visualization, analysis of molecular interactions and the study of cavities in molecular structures. However, if one is interested in the surface that is accessible to a molecule whose shape differs significantly from a sphere, a different concept is necessary. To address this problem, we generalize the definition of the SES by replacing the probe sphere with the full geometry of the ligand defined by the arrangement of its van der Waals spheres. We call the new surface ligand excluded surface (LES) and present an efficient, grid-based algorithm for its computation. Furthermore, we show that this algorithm can also be used to compute molecular cavities that could host the ligand molecule. We provide a detailed description of its implementation on CPU and GPU. Furthermore, we present a performance and convergence analysis and compare the LES for several molecules, using as ligands either water or small organic molecules.},
author = {Lindow, Norbert and Baum, Daniel and Hege, Hans Christian},
doi = {10.1109/TVCG.2014.2346404},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/SupplementalMaterial/2486{\_}supMat/2486{\_}supMat.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Molecular visualization,cavity analysis,ligand excluded surface,solvent excluded surface},
number = {12},
pages = {2486--2495},
title = {{Ligand excluded surface: A new type of molecular surface}},
volume = {20},
year = {2014}
}
@article{Misue2014,
author = {Misue, Kazuo and Taguchi, Kiyohisa},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/misue.pdf:pdf},
journal = {IEEE Information Visualization},
title = {{Emotion-Weather Maps: Representation of Spatial Distributions of Mass and Complex Emotions}},
year = {2014}
}
@article{Xie2014a,
abstract = {Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET.},
author = {Xie, Cong and Chen, Wei and Huang, Xinxin and Hu, Yueqi and Barlowe, Scott and Yang, Jing},
doi = {10.1109/TVCG.2014.2346913},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1743{\_}20tvcg12-xie-2346913.pdf:pdf},
isbn = {1077-2626 VO  - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {E-transaction,Time-Series,Visual Analytics},
number = {12},
pages = {1743--1752},
title = {{VAET: A visual analytics approach for e-transactions time-series}},
volume = {20},
year = {2014}
}
@article{Gunther2014b,
abstract = {Data acquisition, numerical inaccuracies, and sampling often introduce noise in measurements and simulations. Removing this noise is often necessary for efficient analysis and visualization of this data, yet many denoising techniques change the minima and maxima of a scalar field. For example, the extrema can appear or disappear, spatially move, and change their value. This can lead to wrong interpretations of the data, e.g., when the maximum temperature over an area is falsely reported being a few degrees cooler because the denoising method is unaware of these features. Recently, a topological denoising technique based on a global energy optimization was proposed, which allows the topology-controlled denoising of 2D scalar fields. While this method preserves the minima and maxima, it is constrained by the size of the data. We extend this work to large 2D data and medium-sized 3D data by introducing a novel domain decomposition approach. It allows processing small patches of the domain independently while still avoiding the introduction of new critical points. Furthermore, we propose an iterative refinement of the solution, which decreases the optimization energy compared to the previous approach and therefore gives smoother results that are closer to the input. We illustrate our technique on synthetic and real-world 2D and 3D data sets that highlight potential applications.},
author = {Gunther, David and Jacobson, Alec and Reininghaus, Jan and Seidel, Hans-Peter and Sorkine-Hornung, Olga and Weinkauf, Tino},
doi = {10.1109/TVCG.2014.2346432},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/SupplementalMaterial/2585{\_}supMat/2585{\_}supMat{\_}02.pdf:pdf},
isbn = {1077-2626},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {2D scalar fields,3D scalar fields,Data acquisitions,Noise measurement,Noise reduction,Numerical models,Numerical optimization,Scalar fields,Three-dimensional displays,Two-dimensional displays,data acquisition,data visualisation,data visualization,global energy optimization,iterative methods,iterative refinement,measurement errors,measurement noise,medium-sized 3D data,memory-efficient topological denoising technique,numerical inaccuracies,real-world 2D data sets,real-world 3D data sets,sampling method,sampling methods,scalar field maxima,scalar field minima,scalar fields,solid modelling,topology,topology-controlled denoising},
number = {12},
pages = {2585--2594},
title = {{Fast and Memory-Efficienty Topological Denoising of 2D and 3D Scalar Fields}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6875939},
volume = {20},
year = {2014}
}
@article{Abdul-Rahman2014,
abstract = {Crowdsourcing platforms, such as Amazon'sMechanical Turk (MTurk), are providing visualization researchers with a new avenue for conducting empirical studies. While such plat- forms offer several advantages over lab-based studies, they also feature some "unknown" or "uncontrolled" variables, which could potentially introduce serious confounding ef- fects in the resultant measurement data. In this paper, we present our experience of using repeated measures in three empirical studies using MTurk. Each study presented par- ticipants with a set of stimuli, each featuring a condition of an independent variable. Participants were exposed to stim- uli repeatedly in a pseudo-random order through four trials and their responses were measured digitally. Only a small portion of the participants were able to perform with abso- lute consistency for all stimuli throughout each experiment. This suggests that a repeated measures design is highly de- sirable (if not essential) when designing empirical studies for crowdsourcing platforms. Additionally, the majority of par- ticipants performed their tasks with reasonable consistency when all stimuli in an experiment are considered collectively. In other words, to most participants, inconsistency occurred occasionally. This suggests that crowdsourcing remains a valid experimental environment, provided that one can inte- grate the means to observe and alleviate the potential con- founding effects of "unknown" or "uncontrolled" variables in the design of the experiment. Copyright {\textcopyright} 2014 ACM.},
author = {Abdul-Rahman, Alfie and Proctor, Karl J. and Duffy, Brian and Chen, Min},
doi = {10.1145/2669557.2669561},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p095-abdulrahman.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
keywords = {all or part of,empirical studies,is granted without fee,mechanical turk,not,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for},
number = {i},
pages = {95--102},
title = {{Repeated measures design in crowdsourcing-based experiments for visualization}},
url = {http://dl.acm.org/citation.cfm?doid=2669557.2669561},
year = {2014}
}
@article{Janetzko2015,
abstract = {Soccer is one the most popular sports today and also very interesting from an scientific point of view. We present a system for analyzing high-frequency position-based soccer data at various levels of detail, allowing to interactively explore and analyze for movement features and game events. Our Visual Analytics method covers single-player, multi-player and event-based analytical views. Depending on the task the most promising features are semi-automatically selected, processed, and visualized. Our aim is to help soccer analysts in finding the most important and interesting events in a match. We present a flexible, modular, and expandable layer-based system allowing in-depth analysis. The integration of Visual Analytics techniques into the analysis process enables the analyst to find interesting events based on classification and allows, by a set of custom views, to communicate the found results. The feedback loop in the Visual Analytics pipeline helps to further improve the classification results. We evaluate our approach by investigating real-world soccer matches and collecting additional expert feedback. Several use cases and findings illustrate the capabilities of our approach.},
author = {Janetzko, Halld'Or and Sacha, Dominik and Stein, Manuel and Schreck, Tobias and Keim, Daniel A. and Deussen, Oliver},
doi = {10.1109/VAST.2014.7042477},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/janetzko.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Soccer Analysis,Sport Analytics,Visual Analytics},
pages = {13--22},
title = {{Feature-driven visual analytics of soccer data}},
year = {2015}
}
@article{Machado2014,
abstract = {We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains.},
author = {Machado, Gustavo and Sadlo, Filip and M{\"{u}}ller, Thomas and Ertl, Thomas},
doi = {10.1109/TVCG.2014.2346442},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2604{\_}20tvcg12-machado-2346442.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Coronal hole extraction,Isocline surfaces,Streamline behavior,Vector field topology},
number = {12},
pages = {2604--2613},
pmid = {26356974},
title = {{Escape maps}},
volume = {20},
year = {2014}
}
@article{Wong2014a,
abstract = {Evaluation is typically seen as a validation tool for visualization, but the proliferation of web-based visualization is enabling a radical new approach that uses crowdsourced evaluation for emergent collaboration where one user's efforts facilitate a crowd of future users. The idea is simple: instead of using clickstreams, keyboard input, and interaction logs to collect performance metrics for individual participants in a user study, the interaction data is aggregated from the running visualization, integrated back into the visual representation, and then the new interaction data is collected and evaluated with the old data. Known as social navigation, this enables users to build on the work of previous users, for example by seeing collective annotations, the most commonly selected data points, and the most popular locations on the visual space. However, while web-based visualizations by definition are distributed using a web server, most do not maintain the server-side database connections and aggregation mechanisms to achieve this. To bridge this gap between social navigation, its evaluation and visualization, we present Crowdster, a framework that supports capturing, aggregating, and visualizing user interaction data. We give three examples to showcase the Crowdster framework: a Google Maps app that shows the navigation trails of previous users, a scatterplot matrix that visualizes a density distribution of the most selected data points, and a node-link visualization that supports collective graph layout. Copyright {\textcopyright} 2014 ACM.},
author = {Wong, Yuet Ling and Elmqvist, Niklas},
doi = {10.1145/2669557.2669567},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p087-wong.pdf:pdf},
isbn = {9781450332095},
journal = {Beyond Time and Errors : Novel Evaluation Methods For Visualization (Workshop)},
keywords = {all or part of,client,is granted without fee,not,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,server,social navigation,this work for,web-based visualization},
title = {{Crowdster: Enabling Social Navigation in Web-based Visualization using Crowdsourced Evaluation}},
year = {2014}
}
@article{Hall2014,
author = {Hall, Kyle Wm and Kusalik, Peter G and Carpendale, Sheelagh},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/hall.pdf:pdf},
journal = {IEEE Scientific Visualization},
keywords = {contour plots,free energy surfaces,projections},
pages = {4--5},
title = {{Profile Contour Plots: Alternative Projections of 3D Free Energy Surfaces}},
year = {2014}
}
@article{Ziemkiewicz2014,
author = {Ziemkiewicz, Caroline and Fouse, Adam and Ganberg, Gabriel and Mullins, Ryan and Pfautz, Stacy},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Ziemkiewicz.pdf:pdf},
isbn = {9781479962273},
keywords = {2,5,graph-based data models,h,index terms,information interfaces and presentation,miscellaneous,user interfaces,visual analytics},
pages = {339--340},
title = {{VAST 2014 Mini - Challenge 1 : Team Aptima}},
year = {2014}
}
@article{Szigeti2014,
author = {Szigeti, Steve and Patrasc, Joana and Schnitman, Davis and Diamond, Sara},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/szigeti.pdf:pdf},
journal = {IEEE Scientific Visualization},
title = {{The Stacked-Stacked Bar Graph : A new twist on an old vislualization}},
year = {2014}
}
@article{Landstorfer2015,
abstract = {We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to repre- sent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the “Carpet”). Visualizations that immediately point to areas of suspicious activity without requiring extensive fltering, help net- work engineers investigating unknown computer security inci- dents. Most of them, however, have limited knowledge of ad- vanced visualization techniques, while many designers and data scientists are unfamiliar with computer security topics. To bridge this gap, we developed visualizations together with engineers, fol- lowing a co-creative process. We will show how we explored the scope of the engineers' tasks and how we jointly developed ideas and designs. Our expert evaluation indicates that this visualization helps to scan large parts of log fles quickly and to defne areas of interest for closer inspection.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Landstorfer, Johannes and Herrmann, Ivo and Stange, Jan Erik and Dork, Marian and Wettach, Reto},
doi = {10.1109/VAST.2014.7042483},
eprint = {arXiv:1011.1669v3},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/landstorfer.pdf:pdf},
isbn = {9781479962273},
issn = {1098-6596},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Pixel-oriented techniques,multidimensional data,network security and intrusion,task and requirements analysis},
pages = {73--82},
pmid = {25246403},
title = {{Weaving a carpet from log entries: A network security visualization built with co-creation}},
year = {2015}
}
@article{Sauer2014,
abstract = {Studying the dynamic evolution of time-varying volumetric data is essential in countless scientific endeavors. The ability to isolate and track features of interest allows domain scientists to better manage large complex datasets both in terms of visual understanding and computational efficiency. This work presents a new trajectory-based feature tracking technique for use in joint particle/volume datasets. While traditional feature tracking approaches generally require a high temporal resolution, this method utilizes the indexed trajectories of corresponding Lagrangian particle data to efficiently track features over large jumps in time. Such a technique is especially useful for situations where the volume dataset is either temporally sparse or too large to efficiently track a feature through all intermediate timesteps. In addition, this paper presents a few other applications of this approach, such as the ability to efficiently track the internal properties of volumetric features using variables from the particle data. We demonstrate the effectiveness of this technique using real world combustion and atmospheric datasets and compare it to existing tracking methods to justify its advantages and accuracy. {\textcopyright} 2014 IEEE.},
author = {Sauer, Franz and Yu, Hongfeng and Ma, Kwan Liu},
doi = {10.1109/TVCG.2014.2346423},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2565{\_}20tvcg12-sauer-2346423.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Feature extraction and tracking,Flow visualization,Particle data,Particle trajectories,Volume data},
number = {12},
pages = {2565--2574},
title = {{Trajectory-based flow feature tracking in joint particle/volume datasets}},
volume = {20},
year = {2014}
}
@article{Wang2016,
abstract = {We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.},
author = {Wang, Xiting and Liu, Shixia and Liu, Junlin and Chen, Jianfei and Zhu, Jun and Guo, Baining},
doi = {10.1109/TVCG.2016.2515592},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/liu.pdf:pdf},
isbn = {9781479962273},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Topic graph,graph matching,graph visualization,level-of-detail,user interactions},
number = {12},
pages = {2508--2521},
title = {{TopicPanorama: A Full Picture of Relevant Topics}},
volume = {22},
year = {2016}
}
@article{Singh2014,
author = {Singh, Gaurav Kumar and Doke, Abhay and Kumar, Varun and Bhat, Savita and Pedanekar, Niranjan},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/singh.pdf:pdf},
journal = {IEEE Information Visualization},
keywords = {application domains,heat map,human-centered computing,index terms,information visualization,moocs,stack visualization,text mining,visual,visualization},
pages = {3--4},
title = {{MOOClens: A Peek into MOOCs for Picking MOOCs}},
year = {2014}
}
@article{Kim2014,
author = {Kim, Tanyoung},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/kimtanyoung.pdf:pdf},
journal = {IEEE Information Visualization},
keywords = {location visualization,personal data,quantified self},
pages = {2--3},
title = {{Visual Exploration of Personal Commuting Behaviors}},
year = {2014}
}
@article{Medina2014,
author = {Medina, Bruno Figueiredo and da Silva, Celmar Guimaraes},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/medina.pdf:pdf},
journal = {IEEE Information Visualization},
keywords = {matrix reordering,pqr tree,reordering,smoothing},
title = {{Matrix Reordering Based on PQR Trees, Binarization and Smoothin}},
year = {2014}
}
@article{Blascheck2014a,
author = {Blascheck, Tanja and Ertl, Thomas},
doi = {10.1145/2669557.2669569},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p070-blascheck.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
keywords = {38,evaluating interactive visualizations,eye tracking,finding insights,good visualization is to,interaction,support a user in,the aim of a,visualization},
pages = {70--77},
title = {{Towards analyzing eye tracking data for evaluating interactive visualization systems}},
url = {http://dl.acm.org/citation.cfm?doid=2669557.2669569},
year = {2014}
}
@article{Ko2015,
abstract = {Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their},
author = {Ko, Sungahnn and Afzal, Shehzad and Walton, Simon and Yang, Yang and Chae, Junghoon and Malik, Abish and Jang, Yun and Chen, Min and Ebert, David},
doi = {10.1109/VAST.2014.7042484},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/ko.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {I.3.6 [Computer Graphics]: Methodology and Techniq,I.3.8 [Computer Graphics]: Applications - Visual A},
pages = {83--92},
title = {{Analyzing high-dimensional multivar{\'{i}}ate network links with integrated anomaly detection, highlighting and exploration}},
year = {2015}
}
@article{Mercun2014,
author = {Mer{\v{c}}un, Tanja},
doi = {10.1145/2669557.2669565},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p103-mercun.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
keywords = {information visualization,reaction cards,user experience},
pages = {103--109},
title = {{Evaluation of information visualization techniques}},
url = {http://dl.acm.org/citation.cfm?doid=2669557.2669565},
year = {2014}
}
@article{Zah,
author = {Zah, Jan and Worring, Marcel},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/zahalka/zahalka.pdf:pdf},
title = {{T i , i , i m a}}
}
@article{Gunther2014a,
abstract = {Data acquisition, numerical inaccuracies, and sampling often introduce noise in measurements and simulations. Removing this noise is often necessary for efficient analysis and visualization of this data, yet many denoising techniques change the minima and maxima of a scalar field. For example, the extrema can appear or disappear, spatially move, and change their value. This can lead to wrong interpretations of the data, e.g., when the maximum temperature over an area is falsely reported being a few degrees cooler because the denoising method is unaware of these features. Recently, a topological denoising technique based on a global energy optimization was proposed, which allows the topology-controlled denoising of 2D scalar fields. While this method preserves the minima and maxima, it is constrained by the size of the data. We extend this work to large 2D data and medium-sized 3D data by introducing a novel domain decomposition approach. It allows processing small patches of the domain independently while still avoiding the introduction of new critical points. Furthermore, we propose an iterative refinement of the solution, which decreases the optimization energy compared to the previous approach and therefore gives smoother results that are closer to the input. We illustrate our technique on synthetic and real-world 2D and 3D data sets that highlight potential applications.},
author = {Gunther, David and Jacobson, Alec and Reininghaus, Jan and Seidel, Hans-Peter and Sorkine-Hornung, Olga and Weinkauf, Tino},
doi = {10.1109/TVCG.2014.2346432},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/SupplementalMaterial/2585{\_}supMat/2585{\_}supMat{\_}01.pdf:pdf},
isbn = {1077-2626},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {2D scalar fields,3D scalar fields,Data acquisitions,Noise measurement,Noise reduction,Numerical models,Numerical optimization,Scalar fields,Three-dimensional displays,Two-dimensional displays,data acquisition,data visualisation,data visualization,global energy optimization,iterative methods,iterative refinement,measurement errors,measurement noise,medium-sized 3D data,memory-efficient topological denoising technique,numerical inaccuracies,real-world 2D data sets,real-world 3D data sets,sampling method,sampling methods,scalar field maxima,scalar field minima,scalar fields,solid modelling,topology,topology-controlled denoising},
number = {12},
pages = {2585--2594},
title = {{Fast and Memory-Efficienty Topological Denoising of 2D and 3D Scalar Fields}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6875939},
volume = {20},
year = {2014}
}
@article{Mirzargar2014,
abstract = {In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.},
author = {Mirzargar, Mahsa and Whitaker, Ross T. and Kirby, Robert M.},
doi = {10.1109/TVCG.2014.2346455},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2654{\_}20tvcg12-mirzargar-2346455.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Boxplots,Data depth,Ensemble visualization,Functional data,Nonparametric statistic,Order statistics,Parametric curves,Uncertainty visualization},
number = {12},
pages = {2654--2663},
pmid = {26356979},
title = {{Curve boxplot: Generalization of boxplot for ensembles of curves}},
volume = {20},
year = {2014}
}
@article{Isenberg2014,
abstract = {We analyzed visualization paper keywords supplied for 4366 pa- pers submitted to five main visualization conferences. We describe main keywords, topic areas, and 10-year historic trends from author- chosen keywords for papers published in the IEEE Visualization conference series (now called IEEE VIS) since 2004. Furthermore, we present the KeyVis Web application that allows visualization researchers to easily browse the 2600+ keywords used for IEEE VIS papers of the past 10 years, aiming at more informed and, hence, more effective keyword selections for future visualization publica- tions and efficient search for related work.},
author = {Isenberg, Petra and Isenberg, Tobias and Sedlmair, Michael and Chen, Jian and M{\"{o}}ller, Torsten},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/isenberg.pdf:pdf},
journal = {IEEE Visualization},
keywords = {3 c o -w,and patterns and a,different historical evolution,ethodology,for our analysis of,keywords freely assigned by,ord a nalysis m,research papesr,the authors to their,the visualization research literature,trends,we collected},
title = {{Visualization According To Research Paper Keywords}},
year = {2014}
}
@article{Lopez2014,
abstract = {Our overall vision is to enable researchers to explore 3D datasets with as much immersion as possible, arising both from visuals as well as from interaction . We therefore explore ways to combine an immersive large view of the 3D data with means to intuitively control this view with touch input on a separate mobile monoscopic tablet. This combination has the potential to increase people's acceptance of stereoscopic environments for 3D data visualization since--through touch-based interaction--it puts them in control of their data. Moreover, the indirect manipulation of (stereoscopically displayed) 3D data on a personal touch device has been shown to have potentially more efficient and precise interaction than interaction directly on a large display.},
author = {Lopez, David and Oehlberg, Lora and Doger, Candemir and Isenberg, Tobias},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/lopez.pdf:pdf},
journal = {IEEE Scientific Visualization},
pages = {2--3},
title = {{Tablet-Based Interaction for Immersive 3D Data Exploration}},
url = {https://hal.inria.fr/hal-01062053},
year = {2014}
}
@article{Mittelstadt2014,
author = {Mittelst{\"{a}}dt, Sebastian and Stoffel, Andreas and Schreck, Tobias and Keim, Daniel A and Mittelst, Sebastian and Stoffel, Andreas and Schreck, Tobias and Keim, Daniel A},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/mittelstadt.pdf:pdf},
journal = {IEEE Information Visualization},
title = {{Analysis of Local Data Patterns by Local Adaptive Color Mapping}},
year = {2014}
}
@article{Correll2014,
abstract = {In this position paper, we enumerate two approaches to the evaluation of visualizations which are associated with two approaches to knowledge formation in science: reductionism, which holds that the understanding of complex phenomena is based on the understanding of simpler components; and holism, which states that complex phenomena have characteristics more than the sum of their parts and must be understood as complete, irreducible units. While we believe that each approach has benefits for evaluating visualizations, we claim that strict adherence to one perspective or the other can make it difficult to generate a full evaluative picture of visualization tools and techniques. We argue for movement between and among these perspectives in order to generate knowledge that is both grounded (i.e. its constituent parts work) and validated (i.e. the whole operates correctly). We conclude with examples of techniques which we believe represent movements of this sort from our own work, highlighting areas where we have both "built up" reductionist techniques into larger contexts, and "broken down" holistic techniques to create generalizable knowledge.},
author = {Correll, Michael and Alexander, Eric and Albers, Danielle and Sarikaya, Alper and Gleicher, Michael},
doi = {10.1145/2669557.2669577},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p023-correll.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
pages = {23--26},
title = {{Navigating reductionism and holism in evaluation}},
url = {http://dl.acm.org/citation.cfm?id=2669557.2669577{\%}5Cnhttp://graphics.cs.wisc.edu/Papers/2014/CAASG14{\%}5Cnhttp://graphics.cs.wisc.edu/Papers/2014/CAASG14/{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2669557.2669577},
year = {2014}
}
@article{Zhao2014a,
abstract = {We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.},
author = {Zhao, Jian and Cao, Nan and Wen, Zhen and Song, Yale and Lin, Yu Ru and Collins, Christopher},
doi = {10.1109/TVCG.2014.2346922},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1773{\_}20tvcg12-zhao-2346922.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Retweeting threads,anomaly detection,information visualization,machine learning,social media,visual analytics},
number = {12},
pages = {1773--1782},
pmid = {26356891},
title = {{{\#}FluxFlow: Visual analysis of anomalous information spreading on social media}},
volume = {20},
year = {2014}
}
@article{Kelleher2015,
abstract = {$\backslash$nManaging complex data flows and update patterns is one of the most difficult challenges in interactive data visualization. For example, constructing interactive visualizations with multiple linked views can be a daunting task. Functional reactive programming provides approaches for declaratively specifying data dependency graphs and maintaining them automatically. We argue that functional reactive programming is an appropriate and effective abstraction for interactive data visualization. We demonstrate the effectiveness of our proposed approach in several visualization examples including multiple linked views. We also provide a catalog of reusable reactive visualization components.$\backslash$n},
author = {Kelleher, Curran and Levkowitz, Haim},
doi = {10.1117/12.2078301},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/kelleher.pdf:pdf},
isbn = {9781628414875},
issn = {1996756X},
journal = {Proc. SPIE},
keywords = {-multiple linked views,2,general and how these,infor-,interaction technques,larger context of,mation visualization,operations fit into a,visual information seeking,ward introduced a visualization},
pages = {93970N--93970N--7},
title = {{Reactive data visualizations}},
url = {http://dx.doi.org/10.1117/12.2078301},
volume = {9397},
year = {2015}
}
@article{Wang2014c,
author = {Wang, Junpeng and Yang, Fei and Cao, Yong},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/wang.pdf:pdf},
journal = {IEEE Scientific Visualization},
pages = {0--1},
title = {{Cache-Aware Iso-Surface Volume Rendering with CUDA}},
year = {2014}
}
@article{Huettenberger2014,
abstract = {Topological and structural analysis of multivariate data is aimed at improving the understanding and usage of such data through identification of intrinsic features and structural relationships among multiple variables. We present two novel methods for simplifying so-called Pareto sets that describe such structural relationships. Such simplification is a precondition for meaningful visualization of structurally rich or noisy data. As a framework for simplification operations, we introduce a decomposition of the data domain into regions of equivalent structural behavior and the reachability graph that describes global connectivity of Pareto extrema. Simplification is then performed as a sequence of edge collapses in this graph; to determine a suitable sequence of such operations, we describe and utilize a comparison measure that reflects the changes to the data that each operation represents. We demonstrate and evaluate our methods on synthetic and real-world examples.},
author = {Huettenberger, Lars and Heine, Christian and Garth, Christoph},
doi = {10.1109/TVCG.2014.2346447},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2684{\_}20tvcg12-huettenberger-2346447.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Decomposition,Multivariate topology,Pareto set,Simplification},
number = {12},
pages = {2684--2693},
pmid = {26356982},
title = {{Decomposition and simplification of multivariate data using Pareto sets}},
volume = {20},
year = {2014}
}
@article{Stamps2014,
author = {Stamps, Andrew S and Jankun-Kelly, T. J.},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/stamps.pdf:pdf},
journal = {IEEE Information Visualization},
title = {{A Design Space for Heterodox Methods in Information Visualization}},
year = {2014}
}
@article{Hadhrawi2014,
author = {Hadhrawi, Mohammad and Wang, Yu-Ann and Lex, Alexander and Larson, Kent},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/hadhrawi.pdf:pdf},
journal = {IEEE Information Visualization},
pages = {1--2},
title = {{CreativeCities: Does Infrastructure Influence Creative Hotspots in Cities?}},
year = {2014}
}
@article{Nunes2015,
abstract = {For cancers such as glioblastoma multiforme, there is an increasing interest in defining ”biological target volumes” (BTV), high tumour-burden regions which may be targeted with dose boosts in radiotherapy. The definition of a BTV requires insight into tumour characteristics going beyond conventionally defined radiological abnormalities and anatomical features. Molecular and biochemical imaging techniques, like positron emission tomography, the use of Magnetic Resonance (MR) Imaging contrast agents or MR Spectroscopy deliver this information and support BTV delineation. MR Spectroscopy Imaging (MRSI) is the only non-invasive technique in this list. Studies with MRSI have shown that voxels with certain metabolic signatures are more susceptible to predict the site of relapse. Nevertheless, the discovery of complex relationships between a high number of different metabolites, anatomical, molecular and functional features is an ongoing topic of research - still lacking appropriate tools supporting a smooth workflow by providing data integration and fusion of MRSI data with other imaging modalities. We present a solution bridging this gap which gives fast and flexible access to all data at once. By integrating a customized visualization of the multi-modal and multi-variate image data with a highly flexible visual analytics (VA) framework, it is for the first time possible to interactively fuse, visualize and explore user defined metabolite relations derived from MRSI in combination with markers delivered by other imaging modalities. Real-world medical cases demonstrate the utility of our solution. By making MRSI data available both in a VA tool and in a multi-modal visualization renderer we can combine insights from each side to arrive at a superior BTV delineation. We also report feedback from domain experts indicating significant positive impact in how this work can improve the understanding of MRSI data and its integration into radiotherapy planning.},
author = {Nunes, Miguel and Rowland, Benjamin and Schlachter, Matthias and Ken, Soleakhena and Matkovic, Kresimir and Laprie, Anne and Buhler, Katja},
doi = {10.1109/VAST.2014.7042481},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/nunes.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {MR spectroscopy,brain,cancer,medical decision support systems,multi-modality data,radiotherapy planning,visualization},
pages = {53--62},
title = {{An integrated visual analysis system for fusing MR spectroscopy and multi-modal radiology imaging}},
year = {2015}
}
@article{Smuc,
author = {Smuc, Michael},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p035-smuc.pdf:pdf},
isbn = {9781450332095},
keywords = {all of these points,but,cognitive theory,design,experimentation,have their merits,human factors,insight-methodology,measurement,problem solving,theory,without any doubt},
title = {{Just the other side of the coin ? From error- to insight-analysis}}
}
@article{Brehmer2014b,
abstract = {For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system “in the wild”, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of “exploring” a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology},
author = {Brehmer, Matthew and Ingram, Stephen and Stray, Jonathan and Munzner, Tamara},
doi = {10.1109/TVCG.2014.2346431},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2271{\_}20tvcg12-brehmer-2346431.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Design study,investigative journalism,task and requirements analysis,text analysis,text and document data},
number = {12},
pages = {2271--2280},
title = {{Overview: The design, adoption, and analysis of a visual document mining tool for investigative journalists}},
volume = {20},
year = {2014}
}
@article{Sharma2014,
author = {Sharma, Ankit and Girier, Armand and Yang, Yeonsoo and Nakajima, Nobuyasu},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/sharma.pdf:pdf},
journal = {IEEE Scientific Visualization},
keywords = {10,3,4,6,computer graphics,i,image processing and,index terms,interaction techniques,methodologies and,ray casting,techniques,torrential rain,volume visualization,weather radar,webgl},
pages = {2--3},
title = {{Web based Interactive Visualization of Weather Radar Data}},
year = {2014}
}
@article{Joy2014,
author = {Joy, K},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/tvcg-careerAward-2346669.pdf:pdf},
isbn = {1077-2626},
journal = {Ieee Transactions on Visualization and Computer Graphics},
keywords = {Computer Science},
number = {12},
pages = {XXIV--XXIV},
title = {{The 2014 Visualization Career Award Ken joy}},
volume = {20},
year = {2014}
}
@article{Claudio2014,
author = {Claudio, T and Member, Harish Doraiswamy and Ferreira, Nivan and Member, Student and Damoulas, Theodoros},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2634{\_}20tvcg12-doraiswamy-2346449.pdf:pdf},
number = {12},
pages = {2634--2643},
title = {{Original citation : Using Topological Analysis to Support Event-Guided Exploration in Urban Data}},
volume = {20},
year = {2014}
}
@article{Kurzhals2014,
author = {Kurzhals, Kuno and Bopp, Cyrill Fabian and B{\"{a}}ssler, Jochen and Ebinger, Felix and Weiskopf, Daniel},
doi = {10.1145/2669557.2669558},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p054-kurzhals.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
keywords = {all or part of,evaluation methods,eye tracking,is granted without fee,not,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for,visualization},
pages = {54--60},
title = {{Benchmark data for evaluating visualization and analysis techniques for eye tracking for video stimuli}},
url = {http://dl.acm.org/citation.cfm?doid=2669557.2669558},
year = {2014}
}
@article{Li2014,
author = {Li, Jie and Zhan, Kang},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/li.pdf:pdf},
isbn = {9781479962273},
pages = {133--142},
title = {{Vi smate : Interact tive Visu ual Ana lysis of Station -Based Ob bservati ion Data a on Cli mate C hanges}},
year = {2014}
}
@article{Prieto2014,
author = {Prieto, Diana Fernandez and Triana, Jhon Alejandro and Ibarra, Juan Camilo and Arteaga, Isabel Cristina and Hernadez, Jose Tiberio and Hagen, Hans},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/scivis/posters/prieto.pdf:pdf},
journal = {IEEE Scientific Visualization},
title = {{Radial Visualization for Geo-spatial Categorical Data ´}},
year = {2014}
}
@article{Ragan2014,
author = {Ragan, Eric D. and Goodall, John R.},
doi = {10.1145/2669557.2669563},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p027-ragan.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
keywords = {analytic provenance,evaluation,process memory,visual history},
pages = {27--34},
title = {{Evaluation methodology for comparing memory and communication of analytic processes in visual analytics}},
url = {http://dl.acm.org/citation.cfm?id=2669557.2669563},
year = {2014}
}
@article{Choo2014,
author = {Choo, Jaegul and Han, Yi and Hu, Mengdie and Kim, Hannah and Nugent, James and Poggi, Francesco and Park, Haesun and Stasko, John},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Choo.pdf:pdf},
isbn = {9781479962273},
pages = {347--348},
title = {{Exploring Anomalies in GAStech}},
year = {2014}
}
@article{Wang2014a,
author = {Wang, Florence Ying and Sallaberry, Arnaud and Klein, Karsten and Takatsuka, Masahiro},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/wang.pdf:pdf},
journal = {IEEE Information Visualization},
pages = {3--4},
title = {{Visualizing Time-varying Twitter Data with SentimentClock}},
year = {2014}
}
@article{Stolper2014a,
abstract = {The field of graph visualization has produced a wealth of visualization techniques for accomplishing a variety of analysis tasks. Therefore analysts often rely on a suite of different techniques, and visual graph analysis application builders strive to provide this breadth of techniques. To provide a holistic model for specifying network visualization techniques (as opposed to considering each technique in isolation) we present the Graph-Level Operations (GLO) model. We describe a method for identifying GLOs and apply it to identify five classes of GLOs, which can be flexibly combined to re-create six canonical graph visualization techniques. We discuss advantages of the GLO model, including potentially discovering new, effective network visualization techniques and easing the engineering challenges of building multi-technique graph visualization applications. Finally, we implement the GLOs that we identified into the GLO-STIX prototype system that enables an analyst to interactively explore a graph by applying GLOs.},
author = {Stolper, Charles D. and Kahng, Minsuk and Lin, Zhiyuan and Foerster, Florian and Goel, Aakash and Stasko, John and Chau, Duen Horng},
doi = {10.1109/TVCG.2014.2346444},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2320{\_}20tvcg12-stolper-2346444.pdf:pdf},
isbn = {1077-2626 VO - 20},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Graph analysis,Graph visualization,Graph-level operations,Information visualization,Visualization technique specification},
number = {12},
pages = {2320--2328},
pmid = {26005315},
title = {{GLO-STIX: Graph-level operations for specifying techniques and interactive exploration}},
volume = {20},
year = {2014}
}
@article{Kondo2014,
author = {Kondo, Brittany and Mehta, Hrim and Collins, Christopher},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/kondo.pdf:pdf},
journal = {IEEE Information Visualization},
title = {{Glidgets: Interactive Glyphs for Exploring Dynamic Graphs}},
volume = {1},
year = {2014}
}
@article{Arietta2014,
abstract = {Abstract—We present a method for automatically identifying and validating predictive relationships between the visual appearance of a city and its non-visual attributes (e.g. crime statistics, housing prices, population density etc.). Given a set of street-level images and (location, city-attribute-value) pairs of measurements, we first identify visual elements in the images that are discriminative of the attribute. We then train a predictor by learning a set of weights over these elements using non-linear Support Vector Regression. To performthese operations efficiently, we implement a scalable distributed processing framework that speeds up the main computational bottleneck (extracting visual elements) by an order of magnitude. This speedup allows us to investigate a variety of city attributes across 6 different American cities. We find that indeed there is a predictive relationship between visual elements and a number of city attributes including violent crime rates, theft rates, housing prices, population density, tree presence, graffiti presence, and the perception of danger. We also test human performance for predicting theft based on street-level images and show that our predictor outperforms this baseline with 33{\%}higher accuracy on average. Finally, we present three prototype applications that use our system to (1) define the visual boundary of city neighborhoods, (2) generate walking directions that avoid or seek out exposure to city attributes, and (3) validate user-specified visual elements for prediction.},
author = {Arietta, Sean M. and Efros, Alexei A. and Ramamoorthi, Ravi and Agrawala, Maneesh},
doi = {10.1109/TVCG.2014.2346446},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/SupplementalMaterial/2624{\_}supMat/2624{\_}supMat.pdf:pdf},
isbn = {1077-2626 VO  - 20},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Big data,Computational geography,Data mining,Visual processing},
number = {12},
pages = {2624--2633},
pmid = {26356976},
title = {{City forensics: Using visual elements to predict non-visual city attributes}},
volume = {20},
year = {2014}
}
@article{VanDerCorput2014,
abstract = {A common task in visualization is to quickly find interesting items in large sets. When appropriate metadata is missing, automatic queries are impossible and users have to inspect all elements visually. We compared two fundamentally different, but obvious display modes for this task and investigated the difference with respect to effectiveness, efficiency, and satisfaction. The static mode is based on the page metaphor and presents successive pages with a static grid of items. The moving mode is based on the conveyor belt metaphor and lets a grid of items slide though the screen in a continuous flow. In our evaluation, we applied both modes to the common task of browsing images. We performed two experiments where 18 participants had to search for certain target images in a large image collection. The number of shown images per second (pace) was predefined in the first experiment, and under user control in the second one. We conclude that at a fixed pace, the mode has no significant impact on the recall. The perceived pace is generally slower for moving mode, which causes users to systematically choose for a faster real pace than in static mode at the cost of recall. keeping the average number of target images found per second equal for both modes.},
author = {{Van Der Corput}, Paul and {Van Wijk}, Jarke J.},
doi = {10.1109/TVCG.2014.2346437},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2301{\_}20tvcg12-vandercorput-2346437.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {RSVP,image browsing,image classification,multimedia visualization},
number = {12},
pages = {2301--2309},
title = {{Effects of presentation mode and pace control on performance in image classification}},
volume = {20},
year = {2014}
}
@article{Lu2015,
abstract = {A key analytical task across many domains is model building and exploration for predictive analysis. Data is collected, parsed and analyzed for relationships, and features are selected and mapped to estimate the response of a system under exploration. As social media data has grown more abundant, data can be captured that may potentially represent behavioral patterns in society. In turn, this unstructured social media data can be parsed and integrated as a key factor for predictive intelligence. In this paper, we present a framework for the development of predictive models utilizing social media data. We combine feature selection mechanisms, similarity comparisons and model cross-validation through a variety of interactive visualizations to support analysts in model building and prediction. In order to explore how predictions might be performed in such a framework, we present results from a user study focusing on social media data as a predictor for movie box-office success.},
author = {Lu, Yafeng and Kruger, Robert and Thom, Dennis and Wang, Feng and Koch, Steffen and Ertl, Thomas and Maciejewski, Ross},
doi = {10.1109/VAST.2014.7042495},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/lu.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Feature Selection,Predictive Analytics,Social Media},
pages = {193--202},
title = {{Integrating predictive analytics and social media}},
year = {2015}
}
@article{Woodring,
author = {Woodring, Jonathan and Wang, Peter},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/tutorials/Vis-Analysis-Python/PythonVIS2014.pdf:pdf},
pages = {3--4},
title = {{Visualization and Analysis with Python}}
}
@article{Agranovsky,
author = {Agranovsky, Alexy and Camp, David and Garth, Christoph and Bethel, E Wes and Joy, Kenneth I and Childs, Hank and Agranovsky, Alexy and Camp, David and Garth, Christoph and Bethel, E Wes and Joy, Kenneth I and Childs, Hank},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/ldav/papers/agranovsky.pdf:pdf},
isbn = {9781479952151},
keywords = {compression,flow visualization,high-performance computing,particle advection,pathline interpolation},
pages = {67--75},
title = {{Improved Post Hoc Flow Analysis Via Lagrangian Representations Improved Post Hoc Flow Analysis Via Lagrangian Representations}}
}
@article{Andrienko2015,
abstract = {Repeatedly visited personal and public places were extracted from trajectories by finding spatial clusters of stop points. Temporal patterns of people's presence in the places resulted from spatio-temporal aggregation of the data by the places and hourly intervals within the weekly cycle. Based on these patterns, we identified the meanings or purposes of the places: home, work, breakfast or coffee, lunch and dinner, and dinner or shopping. Meanings of some places could be refined using the credit card transaction data. By representing the place meanings as points on a 2D plane, we built an abstract semantic space and transformed the original trajectories to trajectories in the semantic space. Spatio-temporal aggregation of the transformed trajectories into flows between the semantic places and subsequent clustering of time intervals by the similarity of the flow situations allowed us to reveal the routine movement behaviors. To detect anomalies, we (a) investigated the visits to the places with unknown meanings, and (b) looked for unusual presence times or visit durations at different semantic places. The analysis is scalable since all tools and methods can be applied to much larger data.},
author = {Andrienko, Natalia and Andrienko, Gennady and Fuchs, Georg},
doi = {10.1109/VAST.2014.7042556},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Andrienko.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
pages = {341--342},
title = {{Analysis of mobility behaviors in geographic and semantic spaces}},
year = {2015}
}
@article{Madhavan2014,
abstract = {We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users{\&}{\#}x2019; understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics{\&}{\#}x2014;they are essentially casual experts{\&}{\#}x2014;and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.},
author = {Madhavan, Krishna and Elmqvist, Niklas and Vorvoreanu, Mihaela and Chen, Xin and Wong, Yuetling and Xian, Hanjun and Dong, Zhihua and Johri, Aditya},
doi = {10.1109/TVCG.2014.2346747},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1823{\_}20tvcg12-madhavan-2346747.pdf:pdf},
isbn = {1077-2626 VO  - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {casual visualization,design study,portfolio mining,visual analytics,web-based visualization},
number = {12},
pages = {1823--1832},
pmid = {26356896},
title = {{DIA2: Web-based cyberinfrastructure for visual analysis of funding portfolios}},
volume = {20},
year = {2014}
}
@article{Kurzhals2014a,
abstract = {The application of eye tracking for the evaluation of humans' viewing behavior is a common approach in psychological re- search. So far, the use of this technique for the evaluation of visual analytics and visualization is less prominent. We investigate recent scientific publications from the main visu- alization and visual analytics conferences and journals that include an evaluation by eye tracking. Furthermore, we pro- vide an overview of evaluation goals that can be achieved by eye tracking and state-of-the-art analysis techniques for eye tracking data. Ideally, visual analytics leads to a mixed- initiative cognitive system where the mechanism of distribu- tion is the interaction of the user with visualization environ- ments. Therefore, we also include a discussion of cognitive approaches and models to include the user in the evalua- tion process. Based on our review of the current use of eye tracking evaluation in our field and the cognitive theory, we propose directions of future research on evaluation method- ology, leading to the grand challenge of developing an eval- uation approach to the mixed-initiative cognitive system of visual analytics.},
author = {Kurzhals, Kuno and Fisher, Brian and Burch, Michael and Weiskopf, Daniel},
doi = {10.1145/2669557.2669560},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p061-kurzhals.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors Novel Evaluation Methods for Visualization - BELIV '14},
keywords = {all or part of,evaluation meth-,eye tracking,ods,or hard copies of,permission to make digital,this work for,visual analytics,visual cognition,visualization},
pages = {61--69},
title = {{Evaluating visual analytics with eye tracking}},
url = {http://dl.acm.org/citation.cfm?doid=2669557.2669560},
year = {2014}
}
@article{Schmidt2015,
abstract = {{\textcopyright} 2014 IEEE. Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.},
author = {Schmidt, Johanna and Preiner, Reinhold and Auzinger, Thomas and Wimmer, Michael and Groller, M. Eduard and Bruckner, Stefan},
doi = {10.1109/VAST.2014.7042491},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/schmidt.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {3D data exploration,Visual analysis,comparative visualization,focus+context,mesh comparison},
pages = {153--162},
title = {{YMCA - Your mesh comparison application}},
year = {2015}
}
@article{Reda2014,
abstract = {Visualization practitioners have traditionally focused on eval-uating the outcome of the visual analytic process, as opposed to studying how that process unfolds. Since user strategy would likely influence the outcome of visual analysis and the nature of insights acquired, it is important to understand how the analytic behavior of users is shaped by variations in the design of the visualization interface. This paper presents a technique for evaluating user behavior in exploratory vi-sual analysis scenarios. We characterize visual exploration as a fluid activity involving transitions between mental and interaction states. We show how micro-patterns in these transitions can be captured and analyzed quantitatively to reveal differences in the exploratory behavior of users, given variations in the visualization interface.

Reda, Khairi, et al. "Evaluating user behavior and strategy during visual exploration." Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization. ACM, 2014.},
author = {Reda, Khairi and Johnson, Andrew E and Leigh, Jason and Papka, Michael E},
doi = {10.1145/2669557.2669575},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p041-reda.pdf:pdf},
isbn = {9781450332095},
journal = {Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization.},
keywords = {exploratory visual analysis,insight-based evaluation},
pages = {41--45},
title = {{Evaluating User Behavior and Strategy During Visual Exploration}},
url = {https://pdfs.semanticscholar.org/b689/93169661006f82a29aa651a685ddaccf26ab.pdf},
year = {2014}
}
@article{Chen2015a,
abstract = {In this paper, we propose MovementFinder, a multi-filter visual
analytics system for movement data investigation. Our system integrates
movement information from different datasets. Then with various
visualizations and multiple filters, it is able to summarize the general
movement patterns of a group of people, and help analysts detect
abnormal events. Case studies demonstrate its effectiveness in a
fictious analysis scenario.},
author = {Chen, Siming and Wang, Zuchao and Liu, Zipeng and Wang, Zhenhuang and Wang, Chenglong and Miao, Zhengjie and Yuan, Xiaoru},
doi = {10.1109/VAST.2014.7042558},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Chen{\_}01.pdf:pdf},
isbn = {9781479962273},
issn = {2325-9442},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
pages = {345--346},
title = {{MovementFinder: A multi-filter visual analytics design for movement data investigation}},
year = {2015}
}
@article{Schroeder2014,
abstract = {In biomechanics studies, researchers collect, via experiments or simulations, datasets with hundreds or thousands of trials, each describing the same type of motion (e.g., a neck flexion-extension exercise) but under different conditions (e.g., different patients, different disease states, pre- and post-treatment). Analyzing similarities and differences across all of the trials in these collections is a major challenge. Visualizing a single trial at a time does not work, and the typical alternative of juxtaposing multiple trials in a single visual display leads to complex, difficult-to-interpret visualizations. We address this problem via a new strategy that organizes the analysis around motion trends rather than trials. This new strategy matches the cognitive approach that scientists would like to take when analyzing motion collections. We introduce several technical innovations making trend-centric motion visualization possible. First, an algorithm detects a motion collection's trends via time-dependent clustering. Second, a 2D graphical technique visualizes how trials leave and join trends. Third, a 3D graphical technique, using a median 3D motion plus a visual variance indicator, visualizes the biomechanics of the set of trials within each trend. These innovations are combined to create an interactive exploratory visualization tool, which we designed through an iterative process in collaboration with both domain scientists and a traditionally-trained graphic designer. We report on insights generated during this design process and demonstrate the tool's effectiveness via a validation study with synthetic data and feedback from expert musculoskeletal biomechanics researchers who used the tool to analyze the effects of disc degeneration on human spinal kinematics.},
author = {Schroeder, David and Korsakov, Fedor and Knipe, Carissa Mai Ping and Thorson, Lauren and Ellingson, Arin M. and Nuckley, David and Carlis, John and Keefe, Daniel F.},
doi = {10.1109/TVCG.2014.2346451},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2644{\_}20tvcg12-schroeder-2346451.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Design studies,biomedical and medical visualization,focus + context techniques,integrating spatial and non-spatial data visualiza,visual design},
number = {12},
pages = {2644--2653},
pmid = {26356978},
title = {{Trend-centric motion visualization: Designing and applying a new strategy for analyzing scientific motion collections}},
volume = {20},
year = {2014}
}
@article{Chen2015b,
author = {Chen, Siming and Wang, Chenglong and Liu, Zipeng and Wang, Zhenhuang and Wang, Zuchao and Miao, Zhengjie and Yuan, Xiaoru},
doi = {10.1109/VAST.2014.7042545},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Chen{\_}02.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
pages = {319--320},
title = {{Visual analytics support for collecting and correlating evidence for intelligence analysis}},
year = {2015}
}
@article{Gunther2014,
author = {G{\"{u}}nther, David and Boto, Roberto {\'{A}}lvarez and Contreras-garcia, Julia and Piquemal, Jean-philip and Tierny, Julien},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/SupplementalMaterial/2476{\_}supMat/2476{\_}supMat.pdf:pdf},
pages = {1--4},
title = {{Supplementary Material for Characterizing Molecular Interactions in Chemical Systems}},
year = {2014}
}
@article{Hu2014,
abstract = {In order to visualize and analyze complex collective data, complicated geometric structure of each data is desired to be mapped onto a canonical domain to enable map-based visual exploration. This paper proposes a novel volume-preserving mapping and registration method which facilitates effective collective data visualization. Given two 3-manifolds with the same topology, there exists a mapping between them to preserve each local volume element. Starting from an initial mapping, a volume restoring diffeomorphic flow is constructed as a compressible flow based on the volume forms at the manifold. Such a flow yields equality of each local volume element between the original manifold and the target at its final state. Furthermore, the salient features can be used to register the manifold to a reference template by an incompressible flow guided by a divergence-free vector field within the manifold. The process can retain the equality of local volume elements while registering the manifold to a template at the same time. An efficient and practical algorithm is also presented to generate a volume-preserving mapping and a salient feature registration on discrete 3D volumes which are represented with tetrahedral meshes embedded in 3D space. This method can be applied to comparative analysis and visualization of volumetric medical imaging data across subjects. We demonstrate an example application in multimodal neuroimaging data analysis and collective data visualization.},
author = {Hu, Jiaxi and Zou, Guangyu Jeff and Hua, Jing},
doi = {10.1109/TVCG.2014.2346457},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2664{\_}20tvcg12-hu-2346457.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Volume-preserving mapping,data regularization,data transformation},
number = {12},
pages = {2664--2673},
title = {{Volume-preserving mapping and registration for collective data visualization}},
volume = {20},
year = {2014}
}
@article{Borgoa,
author = {Borgo, Rita},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/tutorials/Glyph-based{\_}Visualization/Glyph-Tutorial-vis2014.pdf:pdf},
title = {{in memory of Matt Ward Ma5 Ward}}
}
@article{Veras2014,
author = {Veras, Rafael and Collins, Christopher},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/veras.pdf:pdf},
journal = {IEEE Information Visualization},
number = {5},
pages = {5--6},
title = {{Prioritizing Nodes in Hierarchical Visualizations with the Tree Cut Model}},
year = {2014}
}
@article{Huang2014,
abstract = {Designing visualization for everyday life is challenging, yet design approaches in this field are not well explored. We propose a design approach that implements data as additional media in an existing information ecosystem rather than within a stand-alone application, hoping to enhance on-going awareness and lower the cost of long-term maintenance. This approach was implemented as a web application that integrates time-varying data as an additional visualization layer in a personal digital calendar. We suggest that personal digital calendars can provide personal context to assist with data interpretation and can lower the barriers of accessing data without interfering with daily routines. We deployed our prototype in two pilot field studies, with data streams from household electricity meters and Fitbit devices, respectively. The preliminary results were encouraging. As a different approach towards designing visualizations that can fit into people's routines, we hope our work can inspire future exploration of design approaches that can bring the power of visualization to people's everyday lives.},
author = {Huang, Dandan and Tory, Melanie and Bartram, Lyn},
doi = {10.13140/RG.2.1.4814.0406},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/huang.pdf:pdf},
journal = {IEEE Information Visualization},
keywords = {data,design approach,digital calendar,personal visualization,time-varying},
number = {November},
pages = {3--4},
title = {{Data in Everyday Life: Visualizing Time-Varying Data on a Calendar}},
url = {http://hcssl.iat.sfu.ca/wp-content/uploads/2015/07/Huang{\_}VIS2014{\_}poster.pdf},
year = {2014}
}
@article{Stitz2014,
abstract = {— Visualizing dynamic graphs is challenging because changing node and edge attributes as well as topological alterations need to be encoded in the visual representation. However, existing approaches such as animation, juxtaposition, and superimposition do not scale well. In this poster we propose a novel layering approach for visualizing dynamic graphs where the graph for each point in time is a single layer and parts of each layer are slightly shifted based on a degree-of-interest (DOI) function. In contrast to 2.5D representations that also use layering, users cannot freely change the viewing perspective but are restricted to the top view, avoiding occlusion and distortion problems. We demonstrate the layering approach by applying the concept to two graph visualizations: a node-link diagram and a radial hierarchy visualization.},
author = {Stitz, Holger and Gratzl, Samuel and Luger, Stefan and Gehlenborg, Nils and Streit, Marc},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/stitz.pdf:pdf},
journal = {IEEE Information Visualization},
title = {{Transparent Layering for Visualizing Dynamic Graphs Using the Flip Book Metaphor}},
year = {2014}
}
@article{Isaacs2014b,
abstract = {With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.},
author = {Isaacs, Katherine E. and Bremer, Peer Timo and Jusufi, Ilir and Gamblin, Todd and Bhatele, Abhinav and Schulz, Martin and Hamann, Bernd},
doi = {10.1109/TVCG.2014.2346456},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2349{\_}20tvcg12-isaacs-2346456.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Information visualization,performance analysis,software visualization,timelines,traces},
number = {12},
pages = {2349--2358},
title = {{Combing the communication hairball: Visualizing parallel execution traces using logical time}},
volume = {20},
year = {2014}
}
@article{Cai2015,
author = {Cai, Zhuang and Chen, Mengyao and Zhao, Hanqing and Zhao, Ying and Zhou, Fangfang and Zhang, Kang},
doi = {10.1109/VAST.2014.7042544},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Cai.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {coordinated multi-view visualization,diverse data sources,visual intelligence analytics,visual reasoning},
pages = {315--317},
title = {{VAST 2014 mini-challenge 1: MEAT - Multiview event analysis tool of diverse data sources}},
year = {2015}
}
@article{Jiang2014,
author = {Jiang, Ming and {Van Essen}, Brian and Harrison, Cyrus and Gokhale, Maya},
doi = {10.1109/LDAV.2014.7013199},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/ldav/papers/jiang.pdf:pdf},
isbn = {9781479952151},
journal = {IEEE Symposium on Large Data Analysis and Visualization 2014, LDAV 2014 - Proceedings},
keywords = {data management,data-intensive computing,memory-map,out-of-core algorithms,streamline tracing},
pages = {11--18},
title = {{Multi-threaded streamline tracing for data-intensive architectures}},
year = {2014}
}
@article{Kim2014a,
author = {Kim, Chris K and Collins, Christopher},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/infovis/posters/kim.pdf:pdf},
journal = {IEEE Information Visualization},
pages = {1--2},
title = {{Lexichrome: Examining Word-Color Associations with Visualization}},
year = {2014}
}
@article{Kim2014b,
abstract = {Designing, conducting, and interpreting evaluation studies with human participants is challenging. While researchers in cognitive psychology, social science, and human-computer interaction view competence in evaluation study methodology a key job skill, it is only recently that visualization researchers have begun to feel the need to learn this skill as well. Acquiring such competence is a lengthy and difficult process fraught with much trial and error. Recent work on patterns for visualization evaluation is now providing much-needed best practices for how to evaluate a visualization technique with human participants. However, negative examples of evaluation methods that fail, yield no usable results, or simply do not work are still missing, mainly because of the difficulty and lack of incentive for publishing negative results or failed research. In this paper, we take the position that there are many good ideas with the best intentions for how to evaluate a visualization tool that simply do not work. We call upon the community to help collect these negative examples in order to show the other side of the coin: what not to do when trying to evaluate visualization.},
author = {Kim, Sung-hee and Yi, Ji Soo and Elmqvist, Niklas},
doi = {10.1145/2669557.2669576},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p142-kim.pdf:pdf},
isbn = {9781450332095},
journal = {BELIV'2014 Beyond the desktop metaphor: Designing Integrated Digital Work Environments},
keywords = {evaluation studies,failures,lessons learned,mistakes},
pages = {142--146},
title = {{Oopsy-Daisy : Failure Stories in Quantitative Evaluation Studies for Visualizations}},
year = {2014}
}
@article{Avila2015,
author = {Avila, Pilar and Guaymas, Amalia and Burgos, Valeria},
doi = {10.1109/VAST.2014.7042541},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Avila.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Visual analysis,dynamic graph,streamgraph,timeline},
pages = {309--310},
title = {{The Kronos Incident (Mini-challenge 1)}},
year = {2015}
}
@article{Scholtz1865,
abstract = {In this paper, we present three case studies of utility evaluations of underlying models in software systems: a user-model, technical and social models both singly and in combination, and a research- based model for user identification. Each of the three cases used a different approach to evaluating the model and each had challenges to overcome in designing and implementing the evaluation. We describe the methods we used and challenges faced in designing the evaluation procedures, summarize the lessons learned, enumerate considerations for those undertaking such evaluations, and present directions for future work.},
author = {Scholtz, Jean and Love, Oriana and Whiting, Mark and Hodges, Duncan and Emanuel, Lia and Stanton, Dana{\"{e}}},
doi = {10.1145/2669557.2669562},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/BELIV/p160-scholtz.pdf:pdf},
isbn = {9781450332095},
journal = {BELIV'2014 Beyond the desktop metaphor: Designing Integrated Digital Work Environments},
keywords = {abstract models,evaluation design,utility evaluation},
pages = {160--167},
title = {{Utility evaluation of models}},
year = {1865}
}
@article{Malik2014b,
author = {Malik, Abish and Maciejewski, Ross and Towers, Sherry and Mccullough, Sean and Ebert, David S},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1863{\_}20tvcg12-malik-2346926.pdf:pdf},
number = {1},
pages = {1863--1872},
title = {{3B - Proactive Spatiotemporal Resource Allocation and Predictive Visual Analytics for Community Policing and Law Enforcement}},
volume = {20},
year = {2014}
}
@article{Lenz2014,
author = {Lenz, Olav and Keul, Frank and Bremm, Sebastian and Hamacher, Kay},
doi = {10.1109/VAST.2014.7042485},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/lenz.pdf:pdf},
isbn = {9781479962273},
journal = {IEEE Visual Analytics Science and Technology},
pages = {93--102},
title = {{Visual Analysis of Patterns in Multiple Amino Acid Mutation Graphs}},
year = {2014}
}
@article{Rubio-Sanchez2014,
abstract = {Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0.1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e.. labeled) axes. similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data.},
author = {Rubio-S{\'{a}}nchez, Manuel and Sanchez, Alberto},
doi = {10.1109/TVCG.2014.2346258},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2013{\_}20tvcg12-rubiosanchez-2346258.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Attribute value estimation,Axis calibration,Biplots,Data centering,Orthographic projection,RadViz,Star Coordinates},
number = {12},
pages = {2013--2022},
title = {{Axis calibration for improving data attribute estimation in star coordinates plots}},
volume = {20},
year = {2014}
}
@article{Clar1972,
author = {Clar, Erich},
doi = {https://doi.org/10.1016/S0014-5793(07)01283-5},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/tvcg-authorsIndex-2359173.pdf:pdf},
isbn = {978-0-471-115840-0},
issn = {0014-5793},
journal = {The Aromatic Sextet},
title = {{Author Index}},
year = {1972}
}
@article{Kamaleswaran2014,
author = {Kamaleswaran, Rishikesan and Pugh, James Edward and Thommandram, Anirudh and James, Andrew and Mcgregor, Carolyn},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/EHR/02-Kamaleswaran-ieeevis2014ehrs{\_}submission{\_}3.pdf:pdf},
journal = {Vizualizing Electronic Health Record Data (Workshop)},
pages = {1--4},
title = {{Visualizing Neonatal Spells: Temporal Visual Analytics of High Frequency Cardiorespiratory Physiological Event Streams}},
year = {2014}
}
@article{Konev2014,
abstract = {In this paper, we introduce a simulation-based approach to design protection plans for flood events. Existing solutions require a lot of computation time for an exhaustive search, or demand for a time-consuming expert supervision and steering. We present a faster alternative based on the automated control of multiple parallel simulation runs. Run Watchers are dedicated system components authorized to monitor simulation runs, terminate them, and start new runs originating from existing ones according to domain-specific rules. This approach allows for a more efficient traversal of the search space and overall performance improvements due to a re-use of simulated states and early termination of failed runs. In the course of search, Run Watchers generate large and complex decision trees. We visualize the entire set of decisions made by Run Watchers using interactive, clustered timelines. In addition, we present visualizations to explain the resulting response plans. Run Watchers automatically generate storyboards to convey plan details and to justify the underlying decisions, including those which leave particular buildings unprotected. We evaluate our solution with domain experts.},
author = {Konev, Artem and Waser, J{\"{u}}rgen and Sadransky, Bernhard and Cornel, Daniel and Perdig{\~{a}}o, Rui A.P. and Horv{\'{a}}th, Zsolt and Gr{\"{o}}ller, M. Eduard},
doi = {10.1109/TVCG.2014.2346930},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/1873{\_}20tvcg12-konev-2346930.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Decision making,Disaster management,Simulation control,Storytelling,Visual evidence},
number = {12},
pages = {1873--1882},
pmid = {26356901},
title = {{Run watchers: Automatic simulation-based decision support in flood management}},
volume = {20},
year = {2014}
}
@article{Guo2014a,
abstract = {This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.},
author = {Guo, Diansheng and Zhu, Xi},
doi = {10.1109/TVCG.2014.2346271},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/TVCG/papers/2043{\_}20tvcg12-guo-2346271.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {flow mapping,generalization,graph drawing,kernel smoothing,multi-resolution mapping,spatial data mining},
number = {12},
pages = {2043--2052},
pmid = {26356918},
title = {{Origin-destination flow data smoothing and mapping}},
volume = {20},
year = {2014}
}
@inproceedings{Wang2015e,
abstract = {Transport assessment plays a vital role in urban planning and traffic control, which are influenced by multi-faceted traffic factors involving road infrastructure and traffic flow. Conventional solutions can hardly meet the requirements and expectations of domain experts. In this paper we present a data-driven solution by leveraging a visual analysis system to evaluate the real traffic situations based on taxi trajectory data. A sketch-based visual interface is designed to support dynamic query and visual reasoning of traffic situations within multiple coordinated views. In particular, we propose a novel road-based query model for analysts to interactively conduct evaluation tasks. This model is supported by a bi-directional hash structure, TripHash, which enables real-time responses to the data queries over a huge amount of trajectory data. Case studies with a real taxi GPS trajectory dataset ({\textgreater} 30GB) show that our system performs well for on-demand transport assessment and reasoning.},
author = {Wang, Fei and Chen, Wei and Wu, Feiran and Zhao, Ye and Hong, Han and Gu, Tianyu and Wang, Long and Liang, Ronghua and Bao, Hujun},
booktitle = {Proceedings of IEEE Conference on Visual Analytics Science and Technology},
doi = {10.1109/VAST.2014.7042486},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/conference-track-papers/wang.pdf:pdf},
isbn = {9781479962273},
keywords = {Hash Index,Road-based Query,Taxi Trajectory,Visual Analysis},
pages = {103--112},
title = {{A visual reasoning approach for data-driven transport assessment on urban roads}},
year = {2015}
}


@article{Fernandes2014,
abstract = {Volumetric depth images (VDI) are a view-dependent representa-tion that combines the high quality of images with the explorability of 3D fields. By compressing the scalar data along view rays into sets of coherent supersegments, VDIs provide an efficient repre-sentation that supports a-posteriori changes of camera parameters. In this paper, we introduce space-time VDIs that achieve the data reduction that is required for efficient in-situ visualization, while still maintaining spatiotemporal flexibility. We provide an efficient space-time representation of VDI streams by exploiting inter-ray and inter-frame coherence, and introduce delta encoding for further data reduction. Our space-time VDI approach exhibits small com-putational overhead, is easy to integrate into existing simulation en-vironments, and may help pave the way toward exascale computing.},
author = {Fernandes, Oliver and Frey, Steffen and Sadlo, Filip and Ertl, Thomas},
doi = {10.1109/LDAV.2014.7013205},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/ldav/papers/fernandes.pdf:pdf},
isbn = {9781479952151},
journal = {IEEE Symposium on Large Data Analysis and Visualization 2014, LDAV 2014 - Proceedings},
keywords = {I.3.3 [Computer Graphics]: Picture/Image Generatio,I.6.6 [Simulation and Modeling]: Simulation Output},
pages = {59--65},
title = {{Space-time volumetric depth images for in-situ visualization}},
year = {2014}
}
@article{Miksch2014,
author = {Miksch, Silvia and Federico, Paolo},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/workshops/EHR/03-FEDERICO-ieeevis2014ehrs{\_}submission{\_}11.pdf:pdf},
journal = {Vizualizing Electronic Health Record Data (Workshop)},
number = {NOVEMBER 2014},
pages = {1--4},
title = {{Knowledge-assisted EHR visualization for cohorts ´}},
year = {2014}
}
@article{Bhaskar2015,
author = {Bhaskar, Rahul Kamal and Paredes, Julia and Shaken, Zahra and Sahaf, Zahra and Alemasoom, Haleh and Anslow, Craig and Maurer, Frank and Sousa, Mario Costa and Samavati, Faramarz},
doi = {10.1109/VAST.2014.7042543},
file = {:D$\backslash$:/02.Paper Archive/VisWeek/VisWeek 14/VIS{\_}Conference/vast/challenge/Bhaskar.pdf:pdf},
isbn = {9781479962273},
journal = {2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings},
keywords = {Visual analytics,criminal investigation,information visualization},
pages = {313--314},
title = {{VACI: Towards visual analytics for criminal investigation}},
year = {2015}
}